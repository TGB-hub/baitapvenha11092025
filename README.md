# baitapvenha11092025
# C√†i ƒë·∫∑t th∆∞ vi·ªán (b·ªè comment n·∫øu ch∆∞a c√†i)
# pip install opencv-python scikit-learn tensorflow matplotlib numpy pillow tkinter

import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import cv2
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import seaborn as sns
import pickle
import time
import random
import tkinter as tk
from tkinter import filedialog, messagebox

print(" ƒê√£ import th√†nh c√¥ng t·∫•t c·∫£ th∆∞ vi·ªán!")
print(f"TensorFlow version: {tf.__version__}")


def select_image_file():
    """
    M·ªü h·ªôp tho·∫°i ƒë·ªÉ ch·ªçn file ·∫£nh t·ª´ m√°y t√≠nh
    """
    # T·∫°o c·ª≠a s·ªï root ·∫©n
    root = tk.Tk()
    root.withdraw()
    
    # Hi·ªÉn th·ªã h·ªôp tho·∫°i ch·ªçn file
    file_path = filedialog.askopenfilename(
        title=" Ch·ªçn ·∫£nh ƒë·ªÉ ph√¢n lo·∫°i m√≥n ƒÉn",
        filetypes=[
            ("T·∫•t c·∫£ ·∫£nh", "*.jpg;*.jpeg;*.png;*.bmp;*.gif;*.tiff"),
            ("JPEG files", "*.jpg;*.jpeg"),
            ("PNG files", "*.png"),
            ("BMP files", "*.bmp"),
            ("GIF files", "*.gif"),
            ("TIFF files", "*.tiff"),
            ("T·∫•t c·∫£ files", "*.*")
        ]
    )
    
    root.destroy()
    return file_path

def show_file_info(file_path):
    """
    Hi·ªÉn th·ªã th√¥ng tin file ·∫£nh
    """
    if os.path.exists(file_path):
        file_size = os.path.getsize(file_path) / 1024  # KB
        print(f" File ƒë∆∞·ª£c ch·ªçn: {os.path.basename(file_path)}")
        print(f" ƒê∆∞·ªùng d·∫´n: {file_path}")
        print(f" K√≠ch th∆∞·ªõc file: {file_size:.1f} KB")
        
        # ƒê·ªçc ·∫£nh ƒë·ªÉ l·∫•y th√¥ng tin
        img = cv2.imread(file_path)
        if img is not None:
            height, width = img.shape[:2]
            channels = img.shape[2] if len(img.shape) == 3 else 1
            print(f" K√≠ch th∆∞·ªõc ·∫£nh: {width}x{height}")
            print(f" S·ªë k√™nh m√†u: {channels}")
        else:
            print(" Kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c ·∫£nh!")
        print("-" * 50)


# Danh s√°ch c√°c m√≥n ƒÉn c·∫ßn ph√¢n lo·∫°i
FOOD_CLASSES = ['Ph·ªü', 'B√∫n B√≤', 'B√°nh X√®o', 'C∆°m T·∫•m', 'B√°nh M√¨']
IMAGE_SIZE = (60, 60)  # K√≠ch th∆∞·ªõc ·∫£nh sau khi resize
NUM_IMAGES_PER_CLASS = 50  # S·ªë ·∫£nh cho m·ªói l·ªõp
BATCH_SIZE = 32
EPOCHS = 50

# ƒê∆∞·ªùng d·∫´n l∆∞u tr·ªØ
DATASET_PATH = 'dataset'
MODEL_PATH = 'food_classifier_model.h5'
DATA_PROCESSED_PATH = 'processed_data.pkl'

# T·∫°o th∆∞ m·ª•c l∆∞u tr·ªØ
os.makedirs('dataset', exist_ok=True)
for food_class in FOOD_CLASSES:
    os.makedirs(f'dataset/{food_class}', exist_ok=True)

print(f" S·∫Ω ph√¢n lo·∫°i {len(FOOD_CLASSES)} lo·∫°i m√≥n ƒÉn:")
for i, food in enumerate(FOOD_CLASSES):
    print(f"   {i+1}. {food}")

def check_existing_model():
    """
    Ki·ªÉm tra xem ƒë√£ c√≥ m√¥ h√¨nh v√† d·ªØ li·ªáu ƒë∆∞·ª£c hu·∫•n luy·ªán ch∆∞a
    """
    model_exists = os.path.exists(MODEL_PATH)
    data_exists = os.path.exists(DATA_PROCESSED_PATH)
    
    print(" Ki·ªÉm tra m√¥ h√¨nh ƒë√£ h·ªçc:")
    print(f"    M√¥ h√¨nh AI: {' C√≥' if model_exists else ' Ch∆∞a c√≥'}")
    print(f"    D·ªØ li·ªáu x·ª≠ l√Ω: {' C√≥' if data_exists else ' Ch∆∞a c√≥'}")
    
    if model_exists and data_exists:
        print(" ƒê√£ t√¨m th·∫•y m√¥ h√¨nh ƒë√£ h·ªçc! S·∫Ω load m√¥ h√¨nh c≈©.")
        return True
    else:
        print(" Ch∆∞a c√≥ m√¥ h√¨nh, s·∫Ω b·∫Øt ƒë·∫ßu h·ªçc t·ª´ ƒë·∫ßu.")
        return False

def generate_synthetic_food_image_bw(food_type, image_index, size=(60, 60)):
    """
    T·∫°o ·∫£nh ƒêEN TR·∫ÆNG cho t·ª´ng lo·∫°i m√≥n ƒÉn v·ªõi ƒë·∫∑c tr∆∞ng ri√™ng
    """
    # T·∫°o ·∫£nh grayscale v·ªõi gi√° tr·ªã ƒë·∫∑c tr∆∞ng cho t·ª´ng m√≥n
    gray_patterns = {
        'Ph·ªü': {
            'base_gray': 120,    # X√°m trung b√¨nh (n∆∞·ªõc ph·ªü)
            'accent_grays': [200, 80, 160, 40]  # C√°c m·ª©c x√°m kh√°c nhau
        },
        'B√∫n B√≤': {
            'base_gray': 80,     # X√°m ƒë·∫≠m (n∆∞·ªõc b√∫n b√≤)
            'accent_grays': [180, 60, 140, 30]
        },
        'B√°nh X√®o': {
            'base_gray': 200,    # X√°m s√°ng (b√°nh x√®o)
            'accent_grays': [100, 150, 70, 220]
        },
        'C∆°m T·∫•m': {
            'base_gray': 240,    # X√°m r·∫•t s√°ng (c∆°m tr·∫Øng)
            'accent_grays': [120, 180, 90, 60]
        },
        'B√°nh M√¨': {
            'base_gray': 160,    # X√°m v·ª´a (b√°nh m√¨)
            'accent_grays': [100, 200, 140, 80]
        }
    }
    
    # T·∫°o ·∫£nh base grayscale
    img = np.ones((size[0], size[1]), dtype=np.uint8)
    pattern = gray_patterns[food_type]
    base_gray = pattern['base_gray']
    
    # Th√™m nhi·ªÖu v√† bi·∫øn th·ªÉ cho base gray
    for i in range(size[0]):
        for j in range(size[1]):
            noise = np.random.randint(-20, 20)
            gray_value = np.clip(base_gray + noise, 0, 255)
            img[i, j] = gray_value
    
    # Th√™m c√°c chi ti·∫øt ƒë·∫∑c tr∆∞ng b·∫±ng c√°c m·ª©c x√°m kh√°c
    accent_grays = pattern['accent_grays']
    num_details = random.randint(8, 20)
    
    for _ in range(num_details):
        # Random position v√† size
        x = random.randint(2, size[0]-8)
        y = random.randint(2, size[1]-8)
        w = random.randint(2, 6)
        h = random.randint(2, 6)
        
        # Random gray value t·ª´ accent grays
        gray_value = random.choice(accent_grays)
        img[x:x+w, y:y+h] = gray_value
    
    # Th√™m texture ƒë·∫∑c tr∆∞ng
    if random.random() > 0.4:
        # Th√™m ƒë∆∞·ªùng k·∫ª (nh∆∞ s·ª£i ph·ªü, b√∫n)
        if food_type in ['Ph·ªü', 'B√∫n B√≤']:
            for _ in range(random.randint(5, 12)):
                start_y = random.randint(0, size[1])
                end_y = random.randint(0, size[1])
                x_pos = random.randint(0, size[0]-1)
                gray_line = random.choice(accent_grays)
                cv2.line(img, (start_y, x_pos), (end_y, x_pos), gray_line, thickness=1)
        
        # Th√™m h√¨nh tr√≤n/oval cho m·ªôt s·ªë m√≥n
        elif food_type in ['B√°nh X√®o', 'C∆°m T·∫•m']:
            for _ in range(random.randint(3, 8)):
                center_x = random.randint(10, size[0]-10)
                center_y = random.randint(10, size[1]-10)
                radius = random.randint(2, 8)
                gray_circle = random.choice(accent_grays)
                cv2.circle(img, (center_y, center_x), radius, gray_circle, -1)
    
    return img

def collect_training_data():
    """
    Thu th·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán b·∫±ng c√°ch t·∫°o ·∫£nh ƒêEN TR·∫ÆNG
    """
    print(" B·∫Øt ƒë·∫ßu thu th·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán...")
    print(f" S·∫Ω t·∫°o {NUM_IMAGES_PER_CLASS} ·∫£nh ƒêEN TR·∫ÆNG cho m·ªói l·ªõp")
    
    total_images = 0
    
    for class_idx, food_class in enumerate(FOOD_CLASSES):
        print(f"\n ƒêang t·∫°o ·∫£nh ƒêEN TR·∫ÆNG cho {food_class}...")
        
        for img_idx in range(NUM_IMAGES_PER_CLASS):
            # T·∫°o ·∫£nh ƒêEN TR·∫ÆNG
            synthetic_img_bw = generate_synthetic_food_image_bw(food_class, img_idx)
            
            # L∆∞u ·∫£nh (·∫£nh ƒë√£ l√† grayscale)
            img_path = f'dataset/{food_class}/img_{img_idx:03d}.jpg'
            cv2.imwrite(img_path, synthetic_img_bw)
            
            total_images += 1
            
            # Hi·ªÉn th·ªã ti·∫øn tr√¨nh
            if (img_idx + 1) % 10 == 0:
                print(f"    ƒê√£ t·∫°o {img_idx + 1}/{NUM_IMAGES_PER_CLASS} ·∫£nh ƒêEN TR·∫ÆNG")
    
    print(f"\n Ho√†n th√†nh! ƒê√£ t·∫°o t·ªïng c·ªông {total_images} ·∫£nh ƒêEN TR·∫ÆNG")
    
    # Hi·ªÉn th·ªã m·ªôt s·ªë ·∫£nh m·∫´u ƒêEN TR·∫ÆNG
    fig, axes = plt.subplots(1, 5, figsize=(15, 3))
    fig.suptitle(' M·∫´u ·∫£nh ƒêEN TR·∫ÆNG ƒë√£ t·∫°o (60x60)', fontsize=16)
    
    for i, food_class in enumerate(FOOD_CLASSES):
        img_path = f'dataset/{food_class}/img_000.jpg'
        img_bw = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        
        axes[i].imshow(img_bw, cmap='gray')
        axes[i].set_title(f'{food_class}', fontsize=12)
        axes[i].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    return total_images


def load_and_preprocess_data():
    """
    Load v√† x·ª≠ l√Ω d·ªØ li·ªáu: ƒë√£ l√† grayscale 60x60, ch·ªâ c·∫ßn normalize
    """
    print(" ƒêang load v√† x·ª≠ l√Ω d·ªØ li·ªáu...")
    
    X = []  # D·ªØ li·ªáu ·∫£nh
    y = []  # Nh√£n
    
    for class_idx, food_class in enumerate(FOOD_CLASSES):
        class_path = f'dataset/{food_class}'
        image_files = [f for f in os.listdir(class_path) if f.endswith(('.jpg', '.png', '.jpeg'))]
        
        print(f" {food_class}: {len(image_files)} ·∫£nh ƒêEN TR·∫ÆNG")
        
        for img_file in image_files:
            img_path = os.path.join(class_path, img_file)
            
            # ƒê·ªçc ·∫£nh grayscale (ƒë√£ l√† 60x60)
            img_bw = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            
            # Normalize v·ªÅ [0, 1]
            img_normalized = img_bw.astype(np.float32) / 255.0
            
            X.append(img_normalized)
            y.append(class_idx)
    
    X = np.array(X)
    y = np.array(y)
    
    print(f" ƒê√£ x·ª≠ l√Ω xong!")
    print(f" Shape d·ªØ li·ªáu: X = {X.shape}, y = {y.shape}")
    
    # L∆∞u d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
    with open(DATA_PROCESSED_PATH, 'wb') as f:
        pickle.dump((X, y), f)
    print(f" ƒê√£ l∆∞u d·ªØ li·ªáu x·ª≠ l√Ω v√†o {DATA_PROCESSED_PATH}")
    
    return X, y

def load_processed_data():
    """
    Load d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω t·ª´ file
    """
    print(f" ƒêang load d·ªØ li·ªáu t·ª´ {DATA_PROCESSED_PATH}...")
    with open(DATA_PROCESSED_PATH, 'rb') as f:
        X, y = pickle.load(f)
    print(f" ƒê√£ load xong! Shape: X = {X.shape}, y = {y.shape}")
    return X, y


def create_cnn_model():
    """
    T·∫°o m√¥ h√¨nh CNN ƒë·ªÉ ph√¢n lo·∫°i ·∫£nh ƒêEN TR·∫ÆNG
    """
    model = keras.Sequential([
        # Input layer
        layers.Input(shape=(60, 60, 1)),
        
        # Convolutional layers
        layers.Conv2D(32, (3, 3), activation='relu'),
        layers.MaxPooling2D(2, 2),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D(2, 2),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D(2, 2),
        
        # Flatten v√† Dense layers
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(64, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(len(FOOD_CLASSES), activation='softmax')
    ])
    
    return model

# Ki·ªÉm tra m√¥ h√¨nh ƒë√£ t·ªìn t·∫°i
has_existing_model = check_existing_model()

if has_existing_model:
    # LOAD M√î H√åNH C≈®
    print("\n ƒêANG LOAD M√î H√åNH ƒê√É H·ªåC...")
    print("="*50)
    
    # Load m√¥ h√¨nh
    model = keras.models.load_model(MODEL_PATH)
    print(f" ƒê√£ load m√¥ h√¨nh t·ª´ {MODEL_PATH}")
    
    # Load d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
    X, y = load_processed_data()
    
    # Chia d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√°
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Reshape cho CNN
    X_test_cnn = X_test.reshape(-1, 60, 60, 1)
    
    # ƒê√°nh gi√° nhanh
    test_loss, test_accuracy = model.evaluate(X_test_cnn, y_test, verbose=0)
    print(f" ƒê·ªô ch√≠nh x√°c m√¥ h√¨nh ƒë√£ h·ªçc: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    print(" M√î H√åNH S·∫¥N S√ÄNG S·ª¨ D·ª§NG!")
    
else:
    # TRAIN M√î H√åNH M·ªöI
    print("\n B·∫ÆT ƒê·∫¶U H·ªåC M·ªöI...")
    print("="*50)
    
    # Thu th·∫≠p d·ªØ li·ªáu
    total_collected = collect_training_data()
    
    # Load v√† x·ª≠ l√Ω d·ªØ li·ªáu
    X, y = load_and_preprocess_data()
    
    # Chia d·ªØ li·ªáu train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f" Train set: {X_train.shape[0]} ·∫£nh")
    print(f" Test set: {X_test.shape[0]} ·∫£nh")
    
    # T·∫°o m√¥ h√¨nh
    print(" ƒêang x√¢y d·ª±ng m√¥ h√¨nh CNN...")
    model = create_cnn_model()
    
    # Compile m√¥ h√¨nh
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # Hi·ªÉn th·ªã c·∫•u tr√∫c m√¥ h√¨nh
    model.summary()
    
    # HU·∫§N LUY·ªÜN M√î H√åNH
    # Reshape d·ªØ li·ªáu cho CNN
    X_train_cnn = X_train.reshape(-1, 60, 60, 1)
    X_test_cnn = X_test.reshape(-1, 60, 60, 1)
    
    print(" B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán m√¥ h√¨nh...")
    print(f"  Epochs: {EPOCHS}")
    print(f"  Batch size: {BATCH_SIZE}")
    
    # Callback ƒë·ªÉ theo d√µi qu√° tr√¨nh hu·∫•n luy·ªán
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=5,
            restore_best_weights=True
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.2,
            patience=3,
            min_lr=0.001
        )
    ]
    
    # Hu·∫•n luy·ªán
    history = model.fit(
        X_train_cnn, y_train,
        batch_size=BATCH_SIZE,
        epochs=EPOCHS,
        validation_data=(X_test_cnn, y_test),
        callbacks=callbacks,
        verbose=1
    )
    
    print(" Ho√†n th√†nh hu·∫•n luy·ªán!")
    
    # L∆ØU M√î H√åNH
    model.save(MODEL_PATH)
    print(f" ƒê√£ l∆∞u m√¥ h√¨nh v√†o {MODEL_PATH}")
    
    # ƒê√°nh gi√° m√¥ h√¨nh
    test_loss, test_accuracy = model.evaluate(X_test_cnn, y_test, verbose=0)
    print(f" ƒê·ªô ch√≠nh x√°c tr√™n test set: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    
    # V·∫Ω bi·ªÉu ƒë·ªì qu√° tr√¨nh hu·∫•n luy·ªán
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
    
    # Accuracy
    ax1.plot(history.history['accuracy'], label='Training Accuracy')
    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')
    ax1.set_title(' Model Accuracy')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True)
    
    # Loss
    ax2.plot(history.history['loss'], label='Training Loss')
    ax2.plot(history.history['val_loss'], label='Validation Loss')
    ax2.set_title(' Model Loss')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend()
    ax2.grid(True)
    
    plt.tight_layout()
    plt.show()

def preprocess_test_image_bw(image_path):
    """
    X·ª≠ l√Ω ·∫£nh test: chuy·ªÉn ƒêEN TR·∫ÆNG, resize 60x60, normalize
    """
    # ƒê·ªçc ·∫£nh
    img = cv2.imread(image_path)
    
    if img is None:
        raise ValueError("Kh√¥ng th·ªÉ ƒë·ªçc ·∫£nh!")
    
    # Chuy·ªÉn sang grayscale NGAY t·ª´ ƒë·∫ßu
    if len(img.shape) == 3:  # N·∫øu l√† ·∫£nh m√†u
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    else:  # N·∫øu ƒë√£ l√† grayscale
        img_gray = img
    
    # Resize v·ªÅ 60x60
    img_resized = cv2.resize(img_gray, IMAGE_SIZE)
    
    # Normalize
    img_normalized = img_resized.astype(np.float32) / 255.0
    
    return img, img_gray, img_resized, img_normalized

def predict_food_image_bw(image_path, show_result=True):
    """
    D·ª± ƒëo√°n lo·∫°i m√≥n ƒÉn t·ª´ ·∫£nh ƒêEN TR·∫ÆNG
    """
    try:
        # X·ª≠ l√Ω ·∫£nh
        img_original, img_gray, img_resized, img_processed = preprocess_test_image_bw(image_path)
        
        # Reshape cho m√¥ h√¨nh
        img_input = img_processed.reshape(1, 60, 60, 1)
        
        # D·ª± ƒëo√°n
        predictions = model.predict(img_input, verbose=0)
        predicted_class_idx = np.argmax(predictions[0])
        confidence = predictions[0][predicted_class_idx] * 100
        
        predicted_food = FOOD_CLASSES[predicted_class_idx]
        
        if show_result:
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            fig, axes = plt.subplots(1, 3, figsize=(15, 5))
            
            # ·∫¢nh g·ªëc
            if len(img_original.shape) == 3:
                img_display = cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB)
                axes[0].imshow(img_display)
            else:
                axes[0].imshow(img_original, cmap='gray')
            axes[0].set_title(' ·∫¢nh g·ªëc', fontsize=14)
            axes[0].axis('off')
            
            # ·∫¢nh grayscale g·ªëc
            axes[1].imshow(img_gray, cmap='gray')
            axes[1].set_title(' ·∫¢nh ƒêEN TR·∫ÆNG', fontsize=14)
            axes[1].axis('off')
            
            # ·∫¢nh cu·ªëi c√πng (60x60)
            axes[2].imshow(img_resized, cmap='gray')
            axes[2].set_title(' 60x60 ƒêEN TR·∫ÆNG', fontsize=14)
            axes[2].axis('off')
            
            plt.tight_layout()
            plt.show()
            
            # K·∫øt qu·∫£ d·ª± ƒëo√°n
            print("="*50)
            print(" K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN")
            print("="*50)
            print(f" M√≥n ƒÉn ƒë∆∞·ª£c d·ª± ƒëo√°n: {predicted_food}")
            print(f" ƒê·ªô tin c·∫≠y: {confidence:.2f}%")
            print("="*50)
            
            # Hi·ªÉn th·ªã t·∫•t c·∫£ x√°c su·∫•t
            print("\n Chi ti·∫øt ƒë·ªô tin c·∫≠y cho t·ª´ng m√≥n:")
            for i, food in enumerate(FOOD_CLASSES):
                prob = predictions[0][i] * 100
                bar = "‚ñà" * int(prob // 2)
                print(f"{food:12}: {prob:6.2f}% {bar}")
        
        return predicted_food, confidence, predictions[0]
    
    except Exception as e:
        print(f" L·ªói: {str(e)}")
        return None, 0, None

def test_image_from_computer():
    """
    Ch·ªçn ·∫£nh t·ª´ m√°y t√≠nh v√† ph√¢n lo·∫°i m√≥n ƒÉn
    """
    print("\n CH·ªåN ·∫¢NH T·ª™ M√ÅY T√çNH")
    print("="*50)
    print(" H∆∞·ªõng d·∫´n:")
    print("    S·∫Ω m·ªü h·ªôp tho·∫°i ch·ªçn file")
    print("    Ch·ªçn ·∫£nh m√≥n ƒÉn t·ª´ m√°y t√≠nh")
    print("    ·∫¢nh s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông chuy·ªÉn th√†nh ƒêEN TR·∫ÆNG v√† resize 60x60")
    print("    AI s·∫Ω d·ª± ƒëo√°n lo·∫°i m√≥n ƒÉn")
    print("="*50)
    
    # M·ªü h·ªôp tho·∫°i ch·ªçn file
    selected_file = select_image_file()
    
    if selected_file:
        # Hi·ªÉn th·ªã th√¥ng tin file
        show_file_info(selected_file)
        
        # Ph√¢n lo·∫°i ·∫£nh
        print(" ƒêang ph√¢n t√≠ch ·∫£nh...")
        result = predict_food_image_bw(selected_file)
        
        if result[0]:
            print(f" Ph√¢n t√≠ch th√†nh c√¥ng!")
        else:
            print(" C√≥ l·ªói x·∫£y ra trong qu√° tr√¨nh ph√¢n t√≠ch!")
            
    else:
        print(" Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c ch·ªçn!")

def test_multiple_images():
    """
    Test nhi·ªÅu ·∫£nh li√™n ti·∫øp
    """
    print("\nüñº TEST NHI·ªÄU ·∫¢NH LI√äN TI·∫æP")
    print("="*50)
    
    while True:
        print("\n Ch·ªçn ·∫£nh ti·∫øp theo ƒë·ªÉ test:")
        test_image_from_computer()
        
        # H·ªèi c√≥ mu·ªën ti·∫øp t·ª•c kh√¥ng
        print("\n" + "="*30)
        choice = input(" B·∫°n c√≥ mu·ªën test th√™m ·∫£nh kh√°c kh√¥ng? (y/n): ").lower().strip()
        
        if choice != 'y' and choice != 'yes':
            break
    
    print(" C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng ph·∫ßn m·ªÅm!")


print("\n" + "="*60)
print(" PH·∫¶N M·ªÄM PH√ÇN LO·∫†I M√ìN ƒÇN VI·ªÜT NAM S·∫¥N S√ÄNG!")
print("="*60)
print(" T√≥m t·∫Øt:")
if not has_existing_model:
    print(f"   ‚Ä¢ ƒê√£ t·∫°o {NUM_IMAGES_PER_CLASS * len(FOOD_CLASSES)} ·∫£nh ƒêEN TR·∫ÆNG")
print(f"   ‚Ä¢ T·∫•t c·∫£ ·∫£nh ƒë·ªÅu ƒë∆∞·ª£c x·ª≠ l√Ω ƒêEN TR·∫ÆNG 60x60")
print(f"   ‚Ä¢ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: {MODEL_PATH}")
print(f"   ‚Ä¢ C√≥ th·ªÉ ph√¢n lo·∫°i {len(FOOD_CLASSES)} m√≥n ƒÉn:")
for i, food in enumerate(FOOD_CLASSES):
    print(f"     {i+1}. {food}")
print("="*60)

print("\n C√ÅCH S·ª¨ D·ª§NG:")
print("    Test 1 ·∫£nh: test_image_from_computer()")
print("    Test nhi·ªÅu ·∫£nh: test_multiple_images()")
print("\n L·∫ßn ch·∫°y ti·∫øp theo s·∫Ω t·ª± ƒë·ªông load m√¥ h√¨nh ƒë√£ h·ªçc!")

print("\n" + "="*60)
print(" B·∫ÆT ƒê·∫¶U TEST NGAY B√ÇY GI·ªú!")
print("="*60)

# T·ª± ƒë·ªông b·∫Øt ƒë·∫ßu test ·∫£nh
test_image_from_computer()
